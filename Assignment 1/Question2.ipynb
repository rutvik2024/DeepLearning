{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive"
      ],
      "metadata": {
        "id": "7LpmSJ4yRWPA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwyVgvjDE1On",
        "outputId": "b83750c0-6579-49f7-c6dd-eae4f9de3510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path of dataset"
      ],
      "metadata": {
        "id": "78dD8NncRe-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = '/content/gdrive/MyDrive/Dataset/Gurumukhi/train/'\n",
        "val_data_path = '/content/gdrive/MyDrive/Dataset/Gurumukhi/val/'"
      ],
      "metadata": {
        "id": "id735nzURebr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Required Library"
      ],
      "metadata": {
        "id": "JnwW9c-dScOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dataset\n",
        "# import torch.utils.data.DataLoader as DataLoader\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gbXkmlb2Rulj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device Config"
      ],
      "metadata": {
        "id": "JUnQJWXzXhbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ],
      "metadata": {
        "id": "My5CrOOBWe5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameters Define"
      ],
      "metadata": {
        "id": "8RjQ4tf6Y4FQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameters define\n",
        "batch_size = 100\n",
        "input_size = 3*32*32 # Image pixel value 3*32*32\n",
        "hidden_size = 100\n",
        "output_size = 10 # Number of classes of an images\n",
        "learning_rate = 0.01\n",
        "tuner = 0.2 # Used for Regularization\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "CYEXpYAuY7hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Composed Transform"
      ],
      "metadata": {
        "id": "iXGKJFgsX0r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(),\n",
        "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                    # transforms.CenterCrop(224),\n",
        "                    transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "JigpWyVjXtb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Dataloader"
      ],
      "metadata": {
        "id": "UYwupZ0-X6BY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "\n",
        "val_dataset = torchvision.datasets.ImageFolder(root=val_data_path, transform=transform)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3iewZ6g_X5Zd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Dataloading"
      ],
      "metadata": {
        "id": "3XYd_XGZbv-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = iter(train_loader)\n",
        "sample, label = next(example)\n",
        "print(example)\n",
        "print(sample.shape, label.shape)\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.imshow(sample[i][0])\n",
        "  print(label[i])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# def imshow(img):\n",
        "#     img = img / 2 + 0.5  # unnormalize\n",
        "#     plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "    \n",
        "    \n",
        "# dataiter = train_loader.__iter__()\n",
        "# images, labels = dataiter.__next__()\n",
        "# images = images.numpy() # convert images to numpy for display# plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(25, 4))\n",
        "# # display 20 images\n",
        "# for idx in np.arange(2):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     imshow(images[idx])\n",
        "\n",
        "\n",
        "# for images, labels in train_loader:\n",
        "#     # do something with images and labels\n",
        "#     #print(f\"Index:, Image shape: {images.shape}, Label shape: {labels.shape}\")\n",
        "#     plt.imshow(images[0])\n",
        "#     break\n",
        "\n",
        "#print(type(train_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "ue2728yRZd2P",
        "outputId": "deaa7cee-6ca6-4349-ccae-bf255459113f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7fbcfb1ab0d0>\n",
            "torch.Size([100, 3, 32, 32]) torch.Size([100])\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor(0)\n",
            "tensor(0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ],
      "metadata": {
        "id": "rq5_1FY-D8xZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huqonWMfzdAV",
        "outputId": "39ec9a7f-add8-4fdc-eb4c-46bd6b5f703d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        # print(x.shape)\n",
        "        hidd = self.l1(x)\n",
        "        hidd = self.relu(hidd)\n",
        "        out = self.l2(hidd)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size)"
      ],
      "metadata": {
        "id": "WS0Y_baKEJOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = model.l1.weight\n",
        "w2 = model.l2.weight\n",
        "\n",
        "# Loss Function\n",
        "loss = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Z3suQKoQLqP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l1_reg():\n",
        "  reg_loss = 0\n",
        "  for param in model.parameters():\n",
        "    reg_loss += torch.sum(torch.abs(param))\n",
        "\n",
        "  return reg_loss"
      ],
      "metadata": {
        "id": "Cs3sBqKSpwyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_reg():\n",
        "  reg_loss = 0\n",
        "  for param in model.parameters():\n",
        "    reg_loss += torch.sum(param**2)\n",
        "\n",
        "  return reg_loss"
      ],
      "metadata": {
        "id": "XcNtTXkoqMji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For L1 Regularaization"
      ],
      "metadata": {
        "id": "qNd9WH_Vqo6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # train loop\n",
        "n_step = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "    n_correct = 0\n",
        "    n_sample = 0\n",
        "\n",
        "    for i, (image,label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predict = model(image)\n",
        "\n",
        "        # Loss\n",
        "        l = loss(predict, label)\n",
        "        \n",
        "        reg_loss = l1_reg()\n",
        "\n",
        "        l += tuner*reg_loss\n",
        "\n",
        "        _, out = torch.max(predict, 1)\n",
        "        n_sample += label.shape[0]\n",
        "        n_correct += (out == label).sum().item()\n",
        "\n",
        "        # Backward Pass\n",
        "        # back_propagation(image, hidd.to(device), label, predict.to(device))\n",
        "        l.backward()\n",
        "\n",
        "        # update weights\n",
        "        with torch.no_grad():\n",
        "            # print(w)\n",
        "            w1 -= learning_rate*w1.grad\n",
        "            w2 -= learning_rate*w2.grad\n",
        "        # zero gradients\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()\n",
        "\n",
        "        # Print value\n",
        "        if epoch%1 == 0:\n",
        "            print(f'epoch : {epoch+1}, loss : {l: .3f}')\n",
        "\n",
        "    acc = 100*(n_correct/n_sample)\n",
        "\n",
        "    print(f\"epoch : {epoch} | accuracy : {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OEezB0MpqEL",
        "outputId": "4fd1b33f-b7b0-4e90-9df8-20dff036bc9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1, loss :  566.648\n",
            "epoch : 1, loss :  457.086\n",
            "epoch : 1, loss :  362.026\n",
            "epoch : 1, loss :  279.862\n",
            "epoch : 1, loss :  210.970\n",
            "epoch : 1, loss :  155.820\n",
            "epoch : 1, loss :  114.617\n",
            "epoch : 1, loss :  86.327\n",
            "epoch : 1, loss :  72.361\n",
            "epoch : 1, loss :  71.145\n",
            "epoch : 0 | accuracy : 0.0\n",
            "epoch : 2, loss :  71.705\n",
            "epoch : 2, loss :  70.665\n",
            "epoch : 2, loss :  70.878\n",
            "epoch : 2, loss :  70.518\n",
            "epoch : 2, loss :  69.931\n",
            "epoch : 2, loss :  69.796\n",
            "epoch : 2, loss :  69.491\n",
            "epoch : 2, loss :  68.978\n",
            "epoch : 2, loss :  68.728\n",
            "epoch : 2, loss :  68.277\n",
            "epoch : 1 | accuracy : 0.0\n",
            "epoch : 3, loss :  68.307\n",
            "epoch : 3, loss :  67.592\n",
            "epoch : 3, loss :  67.645\n",
            "epoch : 3, loss :  67.296\n",
            "epoch : 3, loss :  67.238\n",
            "epoch : 3, loss :  66.833\n",
            "epoch : 3, loss :  66.805\n",
            "epoch : 3, loss :  66.436\n",
            "epoch : 3, loss :  66.322\n",
            "epoch : 3, loss :  66.019\n",
            "epoch : 2 | accuracy : 0.0\n",
            "epoch : 4, loss :  65.980\n",
            "epoch : 4, loss :  65.541\n",
            "epoch : 4, loss :  65.550\n",
            "epoch : 4, loss :  65.301\n",
            "epoch : 4, loss :  65.450\n",
            "epoch : 4, loss :  65.082\n",
            "epoch : 4, loss :  65.102\n",
            "epoch : 4, loss :  64.883\n",
            "epoch : 4, loss :  64.905\n",
            "epoch : 4, loss :  64.641\n",
            "epoch : 3 | accuracy : 0.0\n",
            "epoch : 5, loss :  64.671\n",
            "epoch : 5, loss :  64.366\n",
            "epoch : 5, loss :  64.478\n",
            "epoch : 5, loss :  64.283\n",
            "epoch : 5, loss :  64.521\n",
            "epoch : 5, loss :  64.240\n",
            "epoch : 5, loss :  64.351\n",
            "epoch : 5, loss :  64.232\n",
            "epoch : 5, loss :  64.360\n",
            "epoch : 5, loss :  64.162\n",
            "epoch : 4 | accuracy : 11.4\n",
            "epoch : 6, loss :  64.265\n",
            "epoch : 6, loss :  64.047\n",
            "epoch : 6, loss :  64.237\n",
            "epoch : 6, loss :  64.083\n",
            "epoch : 6, loss :  64.386\n",
            "epoch : 6, loss :  64.137\n",
            "epoch : 6, loss :  64.283\n",
            "epoch : 6, loss :  64.185\n",
            "epoch : 6, loss :  64.335\n",
            "epoch : 6, loss :  64.145\n",
            "epoch : 5 | accuracy : 10.0\n",
            "epoch : 7, loss :  64.259\n",
            "epoch : 7, loss :  64.042\n",
            "epoch : 7, loss :  64.237\n",
            "epoch : 7, loss :  64.082\n",
            "epoch : 7, loss :  64.386\n",
            "epoch : 7, loss :  64.137\n",
            "epoch : 7, loss :  64.283\n",
            "epoch : 7, loss :  64.186\n",
            "epoch : 7, loss :  64.333\n",
            "epoch : 7, loss :  64.145\n",
            "epoch : 6 | accuracy : 10.0\n",
            "epoch : 8, loss :  64.258\n",
            "epoch : 8, loss :  64.042\n",
            "epoch : 8, loss :  64.237\n",
            "epoch : 8, loss :  64.081\n",
            "epoch : 8, loss :  64.386\n",
            "epoch : 8, loss :  64.137\n",
            "epoch : 8, loss :  64.280\n",
            "epoch : 8, loss :  64.189\n",
            "epoch : 8, loss :  64.330\n",
            "epoch : 8, loss :  64.147\n",
            "epoch : 7 | accuracy : 10.0\n",
            "epoch : 9, loss :  64.257\n",
            "epoch : 9, loss :  64.046\n",
            "epoch : 9, loss :  64.233\n",
            "epoch : 9, loss :  64.086\n",
            "epoch : 9, loss :  64.382\n",
            "epoch : 9, loss :  64.143\n",
            "epoch : 9, loss :  64.273\n",
            "epoch : 9, loss :  64.197\n",
            "epoch : 9, loss :  64.323\n",
            "epoch : 9, loss :  64.154\n",
            "epoch : 8 | accuracy : 10.100000000000001\n",
            "epoch : 10, loss :  64.251\n",
            "epoch : 10, loss :  64.052\n",
            "epoch : 10, loss :  64.226\n",
            "epoch : 10, loss :  64.091\n",
            "epoch : 10, loss :  64.377\n",
            "epoch : 10, loss :  64.147\n",
            "epoch : 10, loss :  64.267\n",
            "epoch : 10, loss :  64.202\n",
            "epoch : 10, loss :  64.319\n",
            "epoch : 10, loss :  64.159\n",
            "epoch : 9 | accuracy : 11.200000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L2 Regularization"
      ],
      "metadata": {
        "id": "ys-U-sfTq49y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # train loop\n",
        "n_step = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "    n_correct = 0\n",
        "    n_sample = 0\n",
        "\n",
        "    for i, (image,label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predict = model(image)\n",
        "\n",
        "        # Loss\n",
        "        l = loss(predict, label)\n",
        "        \n",
        "        reg_loss = l2_reg()\n",
        "\n",
        "        l += tuner*reg_loss\n",
        "\n",
        "        _, out = torch.max(predict, 1)\n",
        "        n_sample += label.shape[0]\n",
        "        n_correct += (out == label).sum().item()\n",
        "\n",
        "        # Backward Pass\n",
        "        # back_propagation(image, hidd.to(device), label, predict.to(device))\n",
        "        l.backward()\n",
        "\n",
        "        # update weights\n",
        "        with torch.no_grad():\n",
        "            # print(w)\n",
        "            w1 -= learning_rate*w1.grad\n",
        "            w2 -= learning_rate*w2.grad\n",
        "        # zero gradients\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()\n",
        "\n",
        "        # Print value\n",
        "        if epoch%1 == 0:\n",
        "            print(f'epoch : {epoch+1}, loss : {l: .3f}')\n",
        "\n",
        "    acc = 100*(n_correct/n_sample)\n",
        "\n",
        "    print(f\"epoch : {epoch} | accuracy : {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9039EDnwq6jd",
        "outputId": "54f66802-e791-47e2-8242-631ad25f0eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1, loss :  2.347\n",
            "epoch : 1, loss :  2.327\n",
            "epoch : 1, loss :  2.324\n",
            "epoch : 1, loss :  2.363\n",
            "epoch : 1, loss :  2.472\n",
            "epoch : 1, loss :  2.418\n",
            "epoch : 1, loss :  2.365\n",
            "epoch : 1, loss :  2.468\n",
            "epoch : 1, loss :  2.416\n",
            "epoch : 1, loss :  2.426\n",
            "epoch : 0 | accuracy : 9.700000000000001\n",
            "epoch : 2, loss :  2.340\n",
            "epoch : 2, loss :  2.320\n",
            "epoch : 2, loss :  2.318\n",
            "epoch : 2, loss :  2.356\n",
            "epoch : 2, loss :  2.466\n",
            "epoch : 2, loss :  2.411\n",
            "epoch : 2, loss :  2.359\n",
            "epoch : 2, loss :  2.461\n",
            "epoch : 2, loss :  2.409\n",
            "epoch : 2, loss :  2.420\n",
            "epoch : 1 | accuracy : 10.0\n",
            "epoch : 3, loss :  2.333\n",
            "epoch : 3, loss :  2.314\n",
            "epoch : 3, loss :  2.312\n",
            "epoch : 3, loss :  2.351\n",
            "epoch : 3, loss :  2.460\n",
            "epoch : 3, loss :  2.406\n",
            "epoch : 3, loss :  2.353\n",
            "epoch : 3, loss :  2.455\n",
            "epoch : 3, loss :  2.404\n",
            "epoch : 3, loss :  2.414\n",
            "epoch : 2 | accuracy : 10.0\n",
            "epoch : 4, loss :  2.328\n",
            "epoch : 4, loss :  2.309\n",
            "epoch : 4, loss :  2.307\n",
            "epoch : 4, loss :  2.345\n",
            "epoch : 4, loss :  2.455\n",
            "epoch : 4, loss :  2.400\n",
            "epoch : 4, loss :  2.348\n",
            "epoch : 4, loss :  2.450\n",
            "epoch : 4, loss :  2.399\n",
            "epoch : 4, loss :  2.409\n",
            "epoch : 3 | accuracy : 10.0\n",
            "epoch : 5, loss :  2.323\n",
            "epoch : 5, loss :  2.304\n",
            "epoch : 5, loss :  2.302\n",
            "epoch : 5, loss :  2.341\n",
            "epoch : 5, loss :  2.450\n",
            "epoch : 5, loss :  2.395\n",
            "epoch : 5, loss :  2.343\n",
            "epoch : 5, loss :  2.445\n",
            "epoch : 5, loss :  2.394\n",
            "epoch : 5, loss :  2.404\n",
            "epoch : 4 | accuracy : 10.0\n",
            "epoch : 6, loss :  2.318\n",
            "epoch : 6, loss :  2.299\n",
            "epoch : 6, loss :  2.297\n",
            "epoch : 6, loss :  2.336\n",
            "epoch : 6, loss :  2.446\n",
            "epoch : 6, loss :  2.391\n",
            "epoch : 6, loss :  2.339\n",
            "epoch : 6, loss :  2.441\n",
            "epoch : 6, loss :  2.390\n",
            "epoch : 6, loss :  2.400\n",
            "epoch : 5 | accuracy : 10.0\n",
            "epoch : 7, loss :  2.314\n",
            "epoch : 7, loss :  2.295\n",
            "epoch : 7, loss :  2.293\n",
            "epoch : 7, loss :  2.332\n",
            "epoch : 7, loss :  2.442\n",
            "epoch : 7, loss :  2.387\n",
            "epoch : 7, loss :  2.335\n",
            "epoch : 7, loss :  2.437\n",
            "epoch : 7, loss :  2.386\n",
            "epoch : 7, loss :  2.396\n",
            "epoch : 6 | accuracy : 10.0\n",
            "epoch : 8, loss :  2.310\n",
            "epoch : 8, loss :  2.291\n",
            "epoch : 8, loss :  2.289\n",
            "epoch : 8, loss :  2.328\n",
            "epoch : 8, loss :  2.438\n",
            "epoch : 8, loss :  2.383\n",
            "epoch : 8, loss :  2.331\n",
            "epoch : 8, loss :  2.433\n",
            "epoch : 8, loss :  2.382\n",
            "epoch : 8, loss :  2.392\n",
            "epoch : 7 | accuracy : 10.0\n",
            "epoch : 9, loss :  2.306\n",
            "epoch : 9, loss :  2.287\n",
            "epoch : 9, loss :  2.286\n",
            "epoch : 9, loss :  2.324\n",
            "epoch : 9, loss :  2.434\n",
            "epoch : 9, loss :  2.379\n",
            "epoch : 9, loss :  2.328\n",
            "epoch : 9, loss :  2.430\n",
            "epoch : 9, loss :  2.379\n",
            "epoch : 9, loss :  2.389\n",
            "epoch : 8 | accuracy : 10.0\n",
            "epoch : 10, loss :  2.302\n",
            "epoch : 10, loss :  2.284\n",
            "epoch : 10, loss :  2.283\n",
            "epoch : 10, loss :  2.321\n",
            "epoch : 10, loss :  2.431\n",
            "epoch : 10, loss :  2.376\n",
            "epoch : 10, loss :  2.324\n",
            "epoch : 10, loss :  2.426\n",
            "epoch : 10, loss :  2.375\n",
            "epoch : 10, loss :  2.386\n",
            "epoch : 9 | accuracy : 9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop Out"
      ],
      "metadata": {
        "id": "Kj_TNeeSsnP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout_rate = 0.5\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        # print(x.shape)\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = nn.Dropout(self.dropout_rate)(out)\n",
        "        out = self.l2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size=input_size, hidden_size=hidden_size, output_size=output_size)"
      ],
      "metadata": {
        "id": "iEK_g1HztWs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train loop\n",
        "n_step = len(train_loader)\n",
        "for epoch in range(num_epoch):\n",
        "    n_correct = 0\n",
        "    n_sample = 0\n",
        "\n",
        "    for i, (image,label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predict = model(image)\n",
        "\n",
        "        # Loss\n",
        "        l = loss(predict, label)\n",
        "\n",
        "        _, out = torch.max(predict, 1)\n",
        "        n_sample += label.shape[0]\n",
        "        n_correct += (out == label).sum().item()\n",
        "\n",
        "        # Backward Pass\n",
        "        # back_propagation(image, hidd.to(device), label, predict.to(device))\n",
        "        l.backward()\n",
        "\n",
        "        # update weights\n",
        "        with torch.no_grad():\n",
        "            # print(w)\n",
        "            w1 -= learning_rate*w1.grad\n",
        "            w2 -= learning_rate*w2.grad\n",
        "        # zero gradients\n",
        "        w1.grad.zero_()\n",
        "        w2.grad.zero_()\n",
        "\n",
        "        # Print value\n",
        "        if epoch%1 == 0:\n",
        "            print(f'epoch : {epoch+1}, loss : {l: .3f}')\n",
        "\n",
        "    acc = 100*(n_correct/n_sample)\n",
        "\n",
        "    print(f\"epoch : {epoch} | accuracy : {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-grixC-At4DQ",
        "outputId": "e3c59f4f-4e14-4fcd-b954-134d559bade0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1, loss :  2.253\n",
            "epoch : 1, loss :  2.236\n",
            "epoch : 1, loss :  2.234\n",
            "epoch : 1, loss :  2.273\n",
            "epoch : 1, loss :  2.384\n",
            "epoch : 1, loss :  2.329\n",
            "epoch : 1, loss :  2.277\n",
            "epoch : 1, loss :  2.380\n",
            "epoch : 1, loss :  2.329\n",
            "epoch : 1, loss :  2.339\n",
            "epoch : 0 | accuracy : 9.9\n",
            "epoch : 2, loss :  2.253\n",
            "epoch : 2, loss :  2.236\n",
            "epoch : 2, loss :  2.234\n",
            "epoch : 2, loss :  2.273\n",
            "epoch : 2, loss :  2.384\n",
            "epoch : 2, loss :  2.329\n",
            "epoch : 2, loss :  2.277\n",
            "epoch : 2, loss :  2.379\n",
            "epoch : 2, loss :  2.329\n",
            "epoch : 2, loss :  2.339\n",
            "epoch : 1 | accuracy : 9.8\n",
            "epoch : 3, loss :  2.252\n",
            "epoch : 3, loss :  2.236\n",
            "epoch : 3, loss :  2.234\n",
            "epoch : 3, loss :  2.273\n",
            "epoch : 3, loss :  2.384\n",
            "epoch : 3, loss :  2.328\n",
            "epoch : 3, loss :  2.277\n",
            "epoch : 3, loss :  2.379\n",
            "epoch : 3, loss :  2.329\n",
            "epoch : 3, loss :  2.339\n",
            "epoch : 2 | accuracy : 10.0\n",
            "epoch : 4, loss :  2.251\n",
            "epoch : 4, loss :  2.236\n",
            "epoch : 4, loss :  2.234\n",
            "epoch : 4, loss :  2.273\n",
            "epoch : 4, loss :  2.384\n",
            "epoch : 4, loss :  2.328\n",
            "epoch : 4, loss :  2.277\n",
            "epoch : 4, loss :  2.378\n",
            "epoch : 4, loss :  2.329\n",
            "epoch : 4, loss :  2.338\n",
            "epoch : 3 | accuracy : 11.799999999999999\n",
            "epoch : 5, loss :  2.250\n",
            "epoch : 5, loss :  2.236\n",
            "epoch : 5, loss :  2.234\n",
            "epoch : 5, loss :  2.273\n",
            "epoch : 5, loss :  2.384\n",
            "epoch : 5, loss :  2.328\n",
            "epoch : 5, loss :  2.277\n",
            "epoch : 5, loss :  2.377\n",
            "epoch : 5, loss :  2.329\n",
            "epoch : 5, loss :  2.337\n",
            "epoch : 4 | accuracy : 13.100000000000001\n",
            "epoch : 6, loss :  2.249\n",
            "epoch : 6, loss :  2.235\n",
            "epoch : 6, loss :  2.235\n",
            "epoch : 6, loss :  2.272\n",
            "epoch : 6, loss :  2.384\n",
            "epoch : 6, loss :  2.327\n",
            "epoch : 6, loss :  2.277\n",
            "epoch : 6, loss :  2.376\n",
            "epoch : 6, loss :  2.329\n",
            "epoch : 6, loss :  2.337\n",
            "epoch : 5 | accuracy : 13.3\n",
            "epoch : 7, loss :  2.247\n",
            "epoch : 7, loss :  2.235\n",
            "epoch : 7, loss :  2.235\n",
            "epoch : 7, loss :  2.272\n",
            "epoch : 7, loss :  2.384\n",
            "epoch : 7, loss :  2.327\n",
            "epoch : 7, loss :  2.276\n",
            "epoch : 7, loss :  2.375\n",
            "epoch : 7, loss :  2.329\n",
            "epoch : 7, loss :  2.335\n",
            "epoch : 6 | accuracy : 14.399999999999999\n",
            "epoch : 8, loss :  2.245\n",
            "epoch : 8, loss :  2.235\n",
            "epoch : 8, loss :  2.235\n",
            "epoch : 8, loss :  2.272\n",
            "epoch : 8, loss :  2.384\n",
            "epoch : 8, loss :  2.326\n",
            "epoch : 8, loss :  2.276\n",
            "epoch : 8, loss :  2.373\n",
            "epoch : 8, loss :  2.329\n",
            "epoch : 8, loss :  2.334\n",
            "epoch : 7 | accuracy : 14.299999999999999\n",
            "epoch : 9, loss :  2.242\n",
            "epoch : 9, loss :  2.235\n",
            "epoch : 9, loss :  2.235\n",
            "epoch : 9, loss :  2.272\n",
            "epoch : 9, loss :  2.384\n",
            "epoch : 9, loss :  2.325\n",
            "epoch : 9, loss :  2.275\n",
            "epoch : 9, loss :  2.371\n",
            "epoch : 9, loss :  2.329\n",
            "epoch : 9, loss :  2.332\n",
            "epoch : 8 | accuracy : 14.7\n",
            "epoch : 10, loss :  2.238\n",
            "epoch : 10, loss :  2.235\n",
            "epoch : 10, loss :  2.235\n",
            "epoch : 10, loss :  2.272\n",
            "epoch : 10, loss :  2.384\n",
            "epoch : 10, loss :  2.324\n",
            "epoch : 10, loss :  2.275\n",
            "epoch : 10, loss :  2.369\n",
            "epoch : 10, loss :  2.328\n",
            "epoch : 10, loss :  2.329\n",
            "epoch : 9 | accuracy : 13.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYCibQKht66m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}