# -*- coding: utf-8 -*-
"""M22CS011_Assignment_2_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CZ3G4R1A80siRF0TwFRF_9sLD4u1eVSv
"""

!pip install -U torch==1.7.1 torchtext==0.4.0

# Reload environment
exit()

"""# Importing Required Library"""

import torch
import torchtext
from torchtext.data import Field, BucketIterator
import csv
import torch.nn as nn
from torchtext.datasets import TranslationDataset
from torchtext.data import TabularDataset
import random
import time
import matplotlib.pyplot as plt

"""# Device config"""

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

"""# Drive Mount"""

from google.colab import drive
drive.mount('/content/drive')

"""# File path"""

train_path = '/content/drive/MyDrive/Dataset/Dakshina Dataset/hi/lexicons/hi.translit.sampled.train.tsv'
test_path = '/content/drive/MyDrive/Dataset/Dakshina Dataset/hi/lexicons/hi.translit.sampled.test.tsv'
val_path = '/content/drive/MyDrive/Dataset/Dakshina Dataset/hi/lexicons/hi.translit.sampled.dev.tsv'

"""# Field Cration"""

source_field = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')
target_field = Field(tokenize=list, init_token='<sos>', eos_token='<eos>')

datafields=[('source', source_field), ('target', target_field)]

"""# Create Dataset"""

train_dataset = TabularDataset(path=train_path, format='tsv', fields=[('source', source_field), ('target', target_field)])
# train_dataset, test_dataset, val_dataset = TabularDataset.splits(
#     path='/content/drive/MyDrive/Dataset/Dakshina Dataset/hi/lexicons/',
#     train='hi.translit.sampled.train.tsv',
#     test='hi.translit.sampled.test.tsv',
#     validation = 'hi.translit.sampled.dev.tsv',
#     format='csv',
#     skip_header=True,
#     fields=datafields
# )

"""# Build Vocab"""

source_field.build_vocab(train_dataset.source)
target_field.build_vocab(train_dataset.target)

"""# Hyper Parameter"""

batch_size = 32
teacher_force_ratio = 0.5

"""# Create Iterator for each train, test and val"""

train_iter = BucketIterator(
    dataset = train_dataset,
    batch_size = 32,
    device = device
)

# train_iter, val_iter, test_iter = BucketIterator.splits(
#     datasets=(train_dataset, val_dataset, test_dataset),
#     batch_sizes=(batch_size, batch_size, batch_size),
#     sort_key=lambda x: len(x.text),
#     sort_within_batch=True,
#     device=device
# )

source_field.tokenize('Rutvik')
target_field.tokenize('अंकगणित')

source_field.vocab

"""# Model creation
reference : https://www.youtube.com/watch?v=EoGUlvhRYpk

## Encoder
"""

class Encoder(nn.Module):
    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):
        super(Encoder, self).__init__()
        self.input_dim = input_dim
        self.emb_dim = emb_dim
        self.hid_dim = hid_dim
        self.n_layers = n_layers
        self.dropout = dropout
        
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, src):
        embedded = self.dropout(self.embedding(src))
        outputs, (hidden, cell) = self.rnn(embedded)
        return hidden, cell

"""## Decoder Model"""

class Decoder(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):
        super(Decoder, self).__init__()
        self.output_dim = output_dim
        self.emb_dim = emb_dim
        self.hid_dim = hid_dim
        self.n_layers = n_layers
        self.dropout = dropout
        
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)
        self.out = nn.Linear(hid_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, input, hidden, cell):
        input = input.unsqueeze(0)
        embedded = self.dropout(self.embedding(input))
        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))
        prediction = self.out(output.squeeze(0))
        return prediction, hidden, cell

"""## Seq2Seq model"""

class Seq2Seq(nn.Module):
  def __init__(self, encoder, decoder, device):
    super(Seq2Seq, self).__init__()
    self.encoder = encoder
    self.decoder = decoder
    self.device = device


  def forward(self, src, trg, teacher_forcing_ratio=0.5):
    batch_size = trg.shape[1]
    max_len = trg.shape[0]
    trg_vocab_size = self.decoder.output_dim
    
    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)
    
    hidden, cell = self.encoder(src)
    
    input = trg[0,:]
    
    for t in range(1, max_len):
        output, hidden, cell = self.decoder(input, hidden, cell)
        outputs[t] = output
        teacher_force = random.random() < teacher_forcing_ratio
        top1 = output.argmax(1)
        input = trg[t] if teacher_force else top1
    
    return outputs

"""# Dimension Defination"""

INPUT_DIM = len(source_field.vocab)
OUTPUT_DIM = len(target_field.vocab)

def train(ENC_EMB_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, DEC_DROPOUT):
    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)
    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)
    model = Seq2Seq(enc, dec, device).to(device)

    print(f"Train model for Input Embedding:{ENC_EMB_DIM} | number of encoding and decoding layers : {N_LAYERS} | Hidden layer Size : {HID_DIM} ")

    # Define the optimizer and the loss function
    criterion = nn.CrossEntropyLoss(ignore_index=target_field.vocab.stoi['<pad>'])
    optimizer = torch.optim.Adam(model.parameters())

    N_EPOCHS = 15
    CLIP = 1
    start = time.time()

    corr_tbl = torch.zeros((OUTPUT_DIM, OUTPUT_DIM), dtype=torch.long)
    total_correct = 0
    total_tokens = 0
    
    train_losses = []
    train_accs = []

    for epoch in range(N_EPOCHS):
        epoch_loss = 0
        epoch_correct = 0
        epoch_tokens = 0
        model.train()
        
        for batch in train_iter:
            src = batch.source
            trg = batch.target
            optimizer.zero_grad()
            
            output = model(src, trg)
            
            # trg = [trg len, batch size]
            # output = [trg len, batch size, output dim]
            
            output_dim = output.shape[-1]
            
            output = output[1:].view(-1, output_dim)
            trg = trg[1:].view(-1)
            
            # trg = [(trg len - 1) * batch size]
            # output = [(trg len - 1) * batch size, output dim]
            
            loss = criterion(output, trg)
            loss.backward()
            
            # Clip the gradients to prevent them from exploding
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)
            
            optimizer.step()
            epoch_loss += loss.item()

            # Calculate accuracy and update correlation table
            pred = output.argmax(dim=1)
            correct = pred.eq(trg).sum().item()
            epoch_correct += correct
            total_correct += correct
            epoch_tokens += trg.shape[0]
            total_tokens += trg.shape[0]
            for i, p in enumerate(pred):
                corr_tbl[trg[i]][p] += 1
        
        train_loss = epoch_loss / len(train_iter)
        train_losses.append(train_loss)

        # Calculate accuracy for this epoch
        epoch_accuracy = (epoch_correct / epoch_tokens) * 100
        train_accs.append(epoch_accuracy)

        print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.3f}, Training Accuracy: {epoch_accuracy:.2f}%')
        

    end = time.time()
    print(f"Time taken:  {(end- start) / N_EPOCHS}")
    # Plot training loss and accuracy for all epochs
    fig, ax1 = plt.subplots()

    color = 'tab:red'
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Training Loss', color=color)
    ax1.plot(train_losses, color=color)
    ax1.tick_params(axis='y', labelcolor=color)
    plt.show()
    fig, ax2 = plt.subplots()

    color = 'tab:blue'
    ax1.set_xlabel('Epoch')
    ax2.set_ylabel('Training Accuracy', color=color)
    ax2.plot(train_accs, color=color)
    ax2.tick_params(axis='y', labelcolor=color)

    plt.show()

    print('Correlation Table:')
    for i in range(OUTPUT_DIM):
        row = " ".join([f"{corr_tbl[i][j]:5}" for j in range(OUTPUT_DIM)])
        print(row)

    return model, criterion

model1, criterian1 = train(ENC_EMB_DIM = 16, DEC_EMB_DIM = 16 , HID_DIM = 16, N_LAYERS = 1, ENC_DROPOUT = 0.5, DEC_DROPOUT= 0.5)

def evaluate(model, iterator, criterion):
    model.eval()
    epoch_loss = 0
    epoch_acc = 0
    
    with torch.no_grad():
        for batch in iterator:
            src = batch.source
            trg = batch.target

            output = model(src, trg) # Turn off teacher forcing

            # trg = [trg len, batch size]
            # output = [trg len, batch size, output dim]

            output_dim = output.shape[-1]
            
            output = output[1:].view(-1, output_dim)
            trg = trg[1:].view(-1)

            # trg = [(trg len - 1) * batch size]
            # output = [(trg len - 1) * batch size, output dim]

            loss = criterion(output, trg)
            epoch_loss += loss.item()

            # compute accuracy
            pred = torch.argmax(output, dim=1) # predicted character index
            non_pad_mask = trg != target_field.vocab.stoi['<pad>'] # mask padding positions
            num_correct = torch.sum(pred[non_pad_mask] == trg[non_pad_mask])
            num_non_pad = torch.sum(non_pad_mask)
            acc = num_correct.float() / num_non_pad
            epoch_acc += acc.item()

    return epoch_loss / len(iterator), (epoch_acc / len(iterator)) * 100


test_dataset = TabularDataset(path=test_path, format='tsv', fields=[('source', source_field), ('target', target_field)])
test_iter = BucketIterator(
    dataset=test_dataset,
    batch_size=32,
    device=device
)

test_loss, acc = evaluate(model1, test_iter, criterian1)
print(f'Test Loss: {test_loss:.3f} | Test Accuracy : {acc: .3f}%')

model2, criterian2 = train(ENC_EMB_DIM = 64, DEC_EMB_DIM = 64 , HID_DIM = 64, N_LAYERS = 3, ENC_DROPOUT = 0.5, DEC_DROPOUT= 0.5)

test_loss, acc = evaluate(model2, test_iter, criterian2)
print(f'Test Loss: {test_loss:.3f} | Test Accuracy : {acc: .3f}%')

"""# LSTM with attention layer

## Encoder
"""

class EncoderAtt(nn.Module):
    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):
        super(EncoderAtt, self).__init__()
        self.input_dim = input_dim
        self.emb_dim = emb_dim
        self.hid_dim = hid_dim
        self.n_layers = n_layers
        self.dropout = dropout
        
        self.embedding = nn.Embedding(input_dim, emb_dim)
        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, bidirectional = True, dropout=dropout)
        self.dropout = nn.Dropout(dropout)

        self.fc_hidden = nn.Linear(hid_dim*2, hid_dim)
        self.fc_cell = nn.Linear(hid_dim*2, hid_dim)
        
    def forward(self, src):
        embedded = self.dropout(self.embedding(src))
        enc_states, (hidden, cell) = self.rnn(embedded)

        hidden = self.fc_hidden(torch.cat((hidden[0:1], hidden[1:2]), dim = 2))
        cell = self.fc_cell(torch.cat((cell[0:1], cell[1:2]), dim = 2))
        return enc_states,hidden, cell

"""## Decoder"""

class DecoderAtt(nn.Module):
    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):
        super(DecoderAtt, self).__init__()
        self.output_dim = output_dim
        self.emb_dim = emb_dim
        self.hid_dim = hid_dim
        self.n_layers = n_layers
        self.dropout = dropout
        
        self.energy = nn.Linear(hid_dim*3, 1)
        self.softmax = nn.Softmax(dim = 0)
        self.relu = nn.ReLU()
        self.embedding = nn.Embedding(output_dim, emb_dim)
        self.rnn = nn.LSTM(hid_dim*2 + emb_dim, hid_dim, n_layers, dropout=dropout)
        self.out = nn.Linear(hid_dim, output_dim)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, input, enc_state, hidden, cell):
        input = input.unsqueeze(0)
        embedded = self.dropout(self.embedding(input))

        seq_len = enc_state.shape[0]
        h_reshaped = hidden.repeat(seq_len, 1, 1)
        energy = self.relu(self.energy(torch.cat((h_reshaped, enc_state), dim = 2)))
        attention = self.softmax(energy)
        attention = attention.permute(1, 0, 2)

        enc_state = enc_state.permute(1, 0, 2)

        context_vec = torch.bmm(attention, enc_state).permute(1, 0, 2)

        rnn_input = torch.cat((context_vec, embedded), dim = 2)

        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))
        prediction = self.out(output)

        prediction = prediction.squeeze(0)
        return prediction, hidden, cell

"""# Seq2Seq"""

class Seq2SeqAtt(nn.Module):
  def __init__(self, encoder, decoder, device):
    super(Seq2SeqAtt, self).__init__()
    self.encoder = encoder
    self.decoder = decoder
    self.device = device


  def forward(self, src, trg, teacher_forcing_ratio=0.5):
    batch_size = trg.shape[1]
    max_len = trg.shape[0]
    trg_vocab_size = self.decoder.output_dim
    
    outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)
    
    enc_state, hidden, cell = self.encoder(src)
    
    input = trg[0,:]
    
    for t in range(1, max_len):
        output, hidden, cell = self.decoder(input, enc_state, hidden, cell)
        outputs[t] = output
        teacher_force = random.random() < teacher_forcing_ratio
        top1 = output.argmax(1)
        input = trg[t] if teacher_force else top1
    
    return outputs

def train(ENC_EMB_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT, DEC_DROPOUT):
    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)
    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)
    model = Seq2Seq(enc, dec, device).to(device)

    print(f"Train model for Input Embedding:{ENC_EMB_DIM} | number of encoding and decoding layers : {N_LAYERS} | Hidden layer Size : {HID_DIM} ")

    # Define the optimizer and the loss function
    criterion = nn.CrossEntropyLoss(ignore_index=target_field.vocab.stoi['<pad>'])
    optimizer = torch.optim.Adam(model.parameters())

    N_EPOCHS = 15
    CLIP = 1
    start = time.time()

    corr_tbl = torch.zeros((OUTPUT_DIM, OUTPUT_DIM), dtype=torch.long)
    total_correct = 0
    total_tokens = 0
    
    train_losses = []
    train_accs = []

    for epoch in range(N_EPOCHS):
        epoch_loss = 0
        epoch_correct = 0
        epoch_tokens = 0
        model.train()
        
        for batch in train_iter:
            src = batch.source
            trg = batch.target
            optimizer.zero_grad()
            
            output = model(src, trg)
            
            # trg = [trg len, batch size]
            # output = [trg len, batch size, output dim]
            
            output_dim = output.shape[-1]
            
            output = output[1:].view(-1, output_dim)
            trg = trg[1:].view(-1)
            
            # trg = [(trg len - 1) * batch size]
            # output = [(trg len - 1) * batch size, output dim]
            
            loss = criterion(output, trg)
            loss.backward()
            
            # Clip the gradients to prevent them from exploding
            torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)
            
            optimizer.step()
            epoch_loss += loss.item()

            # Calculate accuracy and update correlation table
            pred = output.argmax(dim=1)
            correct = pred.eq(trg).sum().item()
            epoch_correct += correct
            total_correct += correct
            epoch_tokens += trg.shape[0]
            total_tokens += trg.shape[0]
            for i, p in enumerate(pred):
                corr_tbl[trg[i]][p] += 1
        
        train_loss = epoch_loss / len(train_iter)
        train_losses.append(train_loss)

        # Calculate accuracy for this epoch
        epoch_accuracy = (epoch_correct / epoch_tokens) * 100
        train_accs.append(epoch_accuracy)

        print(f'Epoch: {epoch+1}, Training Loss: {train_loss:.3f}, Training Accuracy: {epoch_accuracy:.2f}%')
        

    end = time.time()
    print(f"Time taken:  {(end- start) / N_EPOCHS}")
    # Plot training loss and accuracy for all epochs
    fig, ax1 = plt.subplots()

    color = 'tab:red'
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Training Loss', color=color)
    ax1.plot(train_losses, color=color)
    ax1.tick_params(axis='y', labelcolor=color)
    plt.show()
    fig, ax2 = plt.subplots()

    color = 'tab:blue'
    ax1.set_xlabel('Epoch')
    ax2.set_ylabel('Training Accuracy', color=color)
    ax2.plot(train_accs, color=color)
    ax2.tick_params(axis='y', labelcolor=color)

    plt.show()

    print('Correlation Table:')
    for i in range(OUTPUT_DIM):
        row = " ".join([f"{corr_tbl[i][j]:5}" for j in range(OUTPUT_DIM)])
        print(row)

    return model, criterion

model1, criterian1 = train(ENC_EMB_DIM = 16, DEC_EMB_DIM = 16 , HID_DIM = 16, N_LAYERS = 1, ENC_DROPOUT = 0.5, DEC_DROPOUT= 0.5)

def evaluate(model, iterator, criterion):
    model.eval()
    epoch_loss = 0
    epoch_acc = 0
    
    with torch.no_grad():
        for batch in iterator:
            src = batch.source
            trg = batch.target

            output = model(src, trg) # Turn off teacher forcing

            # trg = [trg len, batch size]
            # output = [trg len, batch size, output dim]

            output_dim = output.shape[-1]
            
            output = output[1:].view(-1, output_dim)
            trg = trg[1:].view(-1)

            # trg = [(trg len - 1) * batch size]
            # output = [(trg len - 1) * batch size, output dim]

            loss = criterion(output, trg)
            epoch_loss += loss.item()

            # compute accuracy
            pred = torch.argmax(output, dim=1) # predicted character index
            non_pad_mask = trg != target_field.vocab.stoi['<pad>'] # mask padding positions
            num_correct = torch.sum(pred[non_pad_mask] == trg[non_pad_mask])
            num_non_pad = torch.sum(non_pad_mask)
            acc = num_correct.float() / num_non_pad
            epoch_acc += acc.item()

    return epoch_loss / len(iterator), (epoch_acc / len(iterator)) * 100


test_dataset = TabularDataset(path=test_path, format='tsv', fields=[('source', source_field), ('target', target_field)])
test_iter = BucketIterator(
    dataset=test_dataset,
    batch_size=32,
    device=device
)

test_loss, acc = evaluate(model1, test_iter, criterian1)
print(f'Test Loss: {test_loss:.3f} | Test Accuracy : {acc: .3f}%')

model2, criterian2 = train(ENC_EMB_DIM = 64, DEC_EMB_DIM = 64 , HID_DIM = 64, N_LAYERS = 3, ENC_DROPOUT = 0.5, DEC_DROPOUT= 0.5)

test_loss, acc = evaluate(model2, test_iter, criterian2)
print(f'Test Loss: {test_loss:.3f} | Test Accuracy : {acc: .3f}%')

